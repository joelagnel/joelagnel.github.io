
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>LinuxInternals.org</title>
  <meta name="author" content="Joel Fernandes">

  
  <meta name="description" content="Non-maskable interrupts (NMI) is a great debug feature that hardware can provide. Some great Linux kernel features that rely on NMI to work properly &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://www.linuxinternals.org">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <link href="/atom.xml" rel="alternate" title="LinuxInternals.org" type="application/atom+xml">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
  <script>!window.jQuery && document.write(unescape('%3Cscript src="./javascripts/libs/jquery.min.js"%3E%3C/script%3E'))</script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="//fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="//fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-50777115-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><div>
<div style="margin-right:50px;float:left;">
  <h1><a href="/">LinuxInternals.org</a></h1>
  
    <h2>by Joel Fernandes</h2>
  
</div>
<div style="float:left;" class="hnav">
 <a href="/joel">Joel's homepage</a><br>
 <a href="/blog/archives/">Articles</a><br>
 <a href="/resources">My talks and resources</a><br>
</div>
<div style="float:right;">
<img src="/images/peng.png" height=150 width=150>
</div>

<div style="position:absolute; top: 170px" class="hnavtitle">
<a href="http://www.meetup.com/LinuxInternals-org-Embedded-Linux-Training/">Join the internals meetup!</a>
</div>
</div>

</header>
<!--
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/atom.xml" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="https://www.google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:www.linuxinternals.org" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
  <li><a href="/technical-resources/">Resources</a></li>
  <li><a href="/aboutme/">About me</a></li>
</ul>

</nav>
-->
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/12/31/nmi-perf-armv8/">ARMv8 and NMI Support</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-12-31T21:29:26-08:00" pubdate data-updated="true">Dec 31<span>st</span>, 2016</time>
        
           | <a href="/blog/2016/12/31/nmi-perf-armv8/#disqus_thread"
             data-disqus-identifier="http://www.linuxinternals.org/blog/2016/12/31/nmi-perf-armv8/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Non-maskable interrupts (NMI) is a great debug feature that hardware can provide. Some great Linux kernel features that rely on NMI to work properly are:</p>

<ul>
<li><p>Backtrace from all CPUs: A number of places in the kernel rely on dumping the stacks of all CPUs at the time of a failure to determine what was going on. Some of them are <a href="http://lxr.free-electrons.com/source/kernel/hung_task.c">Hung Task detection</a>, <a href="http://lxr.free-electrons.com/source/Documentation/lockup-watchdogs.txt">Hard/soft lockup detector</a> and spinlock debugging code.</p></li>
<li><p>Perf profiling: To be able to profile code that runs in interrupt handlers, or in sections of code that disable interrupts, Perf works well only when NMI is available in the architecture.</p></li>
</ul>


<p>Below is a <a href="http://www.brendangregg.com/FlameGraphs/cpuflamegraphs.html">flamegraph</a> generated with perf and some flamegraph magic, that shows just what happens when perf is used in an architecture like ARM that doesn&rsquo;t support NMI. The flamegraph is generated on an ARMv8 platform:</p>

<p><img src="/images/nmi/flamegraph.png"></p>

<p>As you can see in the area of the flamegraph where the arrow is pointed, a large amount of time is spent in <code>_raw_spin_unlock_irqrestore()</code>. It can baffle anyone looking at this data for the first time, and make them think that most of the time is spent in this function. What&rsquo;s actually happenning is because perf is using a maskable interrupt in ARMv8 to profile, any section of code that disables interrupts will not be see in the flamegraph. In other words perf is unable to peek into sections of code where interrupts are disabled. As a result, when interrupts are reenabled during the <code>_raw_spin_unlock_irqrestore</code>, the perf interrupt routine then kicks in and records the large number of samples that elapsed in the interrupt-disable section. This recording accounts all these samples to the _raw_spin_unlock_restore function, hence the flamegraph anomoly. It is indeed quite sad that ARM still doesn&rsquo;t have a true NMI which perf would love to make use of.</p>

<p>BUT! <a href="https://lkml.org/lkml/2016/8/19/583">Daniel Thomspon</a> has been hard at work trying to simulate Non-maskable interrupts on ARMv8. The idea is <a href="/misc/arm-irq-priortization-white-paper.pdf">based on using interrupt priorities</a> and is the subject of the rest of this post.</p>

<p>To simulate an NMI, Daniel creates 2 groups of interrupts in his patchset. One group is for all &lsquo;normal&rsquo; interrupts, and the other for non-maskable interrupts (NMI). Non-maskable interrupts are assigned a higher priority than the normal interrupt group. Inorder to &lsquo;mask&rsquo; interrupts in this approach, Daniel replaces the regular interrupt masking scheme in the kernel which happens at the CPU-core level, with setting of the interrupt controller&rsquo;s PMR (priority mask register). When the PMR is set to a certain value, only interrupts which have a higher priority than what&rsquo;s in the PMR will be signaled to a CPU core, all other interrupts will be silenced (masked). By using this technique, it is possible to mask normal interrupts while keeping the NMI unmasked all the time.</p>

<p>Just how does he do this? So, a small primer on interrupts in the ARM world.
ARM uses the GIC <a href="http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.dai0176c/ar01s03s01.html">Generic interrupt controller</a> to prioritize and route interrupts to CPU cores. GIC interrupt priorties go from 0 to 255. 0 being highest and 255 being the lowest. By default, the kernel <a href="http://lxr.free-electrons.com/source/include/linux/irqchip/arm-gic.h?v=4.8#L57">assigns priority 0xa0 (192)</a> to all interrupts. He changes this default priority from 0xa0 to 0xc0 (you&rsquo;ll see why).
He then defines what values of PMR would be consider as &ldquo;unmasked&rdquo; vs &ldquo;masked&rdquo;. Masked is 0xb0 and unmasked is 0xf0. This results in the following priorities (greater numbers are lower priority).</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>0xf0 (240 decimal)  (11110000 binary) - Interrupts Unmasked (enabled)
</span><span class='line'>0xc0 (192 decimal)  (11000000 binary) - Normal interrupt priority
</span><span class='line'>0xb0 (176 decimal)  (10110000 binary) - Interrupts masked   (disabled)
</span><span class='line'>0x80 (128 decimal)  (10000000 binary) - Non-maskable interrupts</span></code></pre></td></tr></table></div></figure>


<p>In this new scheme, when interrupts are to be masked (disabled), the PMR is set to 0xf0 and when they are unmasked (enabled), the PMR is set to 0xb0. As you can see, setting the PMR to 0xb0 indeed masks normal interrupts, because 0xb0(PMR) &lt; 0xc0(Normal), however non-maskable interrupts still stay unmasked as 0x80(NMI) &lt; 0xb0(PMR). Also notice that inorder to mask/unmask interrupts, all that needs to be done is flip bit 7 in the PMR (0xb0 &ndash;> 0xf0). Daniel largely uses Bit 7 as the mask bit in the patchset.</p>

<p>Daniel has tested his patchset only on the foundation model yet, but it appears that the patch series with modifications should work on the newer Qualcomm chipsets that have the necessary GIC (Generic interrupt controller) access from the core to muck with IRQ priorities. Also, currently Daniel has only implemented CPU backtrace, more work needs to be done for perf support which I&rsquo;ll look into if I can get backtraces working properly on real silicon first.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/06/18/ftrace-events-mechanism/">Ftrace Events Mechanism</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-06-18T22:29:26-07:00" pubdate data-updated="true">Jun 18<span>th</span>, 2016</time>
        
           | <a href="/blog/2016/06/18/ftrace-events-mechanism/#disqus_thread"
             data-disqus-identifier="http://www.linuxinternals.org/blog/2016/06/18/ftrace-events-mechanism/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Ftrace events are a mechanism that allows different pieces of code in the kernel to &lsquo;broadcast&rsquo; events of interest. Such as a scheduler context-switch <code>sched_switch</code> for example. In the scheduler core&rsquo;s <code>__schedule</code> function, you&rsquo;ll see something like: <code>trace_sched_switch(preempt, prev, next);</code>
This immediately results in a write to a per-cpu ring buffer storing info about what the previous task was, what the next one is, and whether the switch is happening as a result of kernel preemption (versus happening for other reasons such as a task waiting for I/O completion).</p>

<p>Under the hood, these ftrace events are actually implemented using tracepoints. The terms events are tracepoints appear to be used interchangeably, but it appears one could use a trace point if desired without having to do anything with ftrace. Events on the other hand use ftrace.</p>

<p>Let&rsquo;s discuss a bit about how a tracepoint works. Tracepoints are hooks that are inserted into points of code of interest and call a certain function of your choice (also known as a function probe). Inorder for the tracepoint to do anything, you have to register a function using <code>tracepoint_probe_register</code>. Multiple functions can be registered in a single hook. Once your tracepoint is hit, all functions registered to the tracepoint are executed. Also note that if no function is registered to the tracepoint, then the tracepoint is essentially a NOP with zero-overhead. Actually that&rsquo;s a lie, there is a branch (and some space) overhead only although negligible.</p>

<p>Here is the heart of the code that executes when a tracepoint is hit:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#define __DECLARE_TRACE(name, proto, args, cond, data_proto, data_args) \
</span><span class='line'>        extern struct tracepoint __tracepoint_##name;                   \
</span><span class='line'>        static inline void trace_##name(proto)                          \
</span><span class='line'>        {                                                               \
</span><span class='line'>                if (static_key_false(&__tracepoint_##name.key))         \
</span><span class='line'>                        __DO_TRACE(&__tracepoint_##name,                \
</span><span class='line'>                                TP_PROTO(data_proto),                   \
</span><span class='line'>                                TP_ARGS(data_args),                     \
</span><span class='line'>                                TP_CONDITION(cond),,);                  \
</span><span class='line'>                if (IS_ENABLED(CONFIG_LOCKDEP) && (cond)) {             \
</span><span class='line'>                        rcu_read_lock_sched_notrace();                  \
</span><span class='line'>                        rcu_dereference_sched(__tracepoint_##name.funcs);\
</span><span class='line'>                        rcu_read_unlock_sched_notrace();                \
</span><span class='line'>                }                                                       \
</span><span class='line'>        }                                                   </span></code></pre></td></tr></table></div></figure>


<p>The <code>static_key_false</code> in the above code will evaluate to false if there&rsquo;s no probe registered to the tracepoint.</p>

<p>Digging further, <code>__DO_TRACE</code> does the following in <code>include/linux/tracepoint.h</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>#define __DO_TRACE(tp, proto, args, cond, prercu, postrcu)              \
</span><span class='line'>        do {                                                            \
</span><span class='line'>                struct tracepoint_func *it_func_ptr;                    \
</span><span class='line'>                void *it_func;                                          \
</span><span class='line'>                void *__data;                                           \
</span><span class='line'>                                                                        \
</span><span class='line'>                if (!(cond))                                            \
</span><span class='line'>                        return;                                         \
</span><span class='line'>                prercu;                                                 \
</span><span class='line'>                rcu_read_lock_sched_notrace();                          \
</span><span class='line'>                it_func_ptr = rcu_dereference_sched((tp)-&gt;funcs);       \
</span><span class='line'>                if (it_func_ptr) {                                      \
</span><span class='line'>                        do {                                            \
</span><span class='line'>                                it_func = (it_func_ptr)-&gt;func;          \
</span><span class='line'>                                __data = (it_func_ptr)-&gt;data;           \
</span><span class='line'>                                ((void(*)(proto))(it_func))(args);      \
</span><span class='line'>                        } while ((++it_func_ptr)-&gt;func);                \
</span><span class='line'>                }                                                       \
</span><span class='line'>                rcu_read_unlock_sched_notrace();                        \
</span><span class='line'>                postrcu;                                                \
</span><span class='line'>        } while (0)</span></code></pre></td></tr></table></div></figure>


<p>There&rsquo;s a lot going on there, but main part is the loop that goes through all function pointers (probes) that were registered to the tracepoint and calls them one after the other.</p>

<p>Now, here&rsquo;s some secrets. Since all ftrace events are tracepoints under the hood, you can piggy back onto interesting events in your kernel with your own probes. This allows you to write interesting tracers. Infact this is precisely how blktrace works, and also is how SystemTap hooks into ftrace events.
<a href="https://github.com/joelagnel/joel-snips/blob/master/k-patches/cpuhists.diff">Checkout a module I wrote</a> that hooks onto <code>sched_switch</code> to build some histograms. The code there is still buggy but if you mess with it and improve it please share your work.</p>

<p>Now that we know a good amount about tracepoints, ftrace events are easy.</p>

<p>An ftrace event being based on tracepoints, makes full use of it but it has to do more. Ofcourse, it has to write events out to the ring buffer.
When you enable an ftrace event using debug-fs, at that instant the ftrace events framework registers an &ldquo;event probe&rdquo; function at the tracepoint that represents the event. How? Using <code>tracepoint_probe_register</code> just as we discussed.</p>

<p>The code for this is in the file <code>kernel/trace/trace_events.c</code> in function <code>trace_event_reg</code>.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>int trace_event_reg(struct trace_event_call *call,
</span><span class='line'>                    enum trace_reg type, void *data)
</span><span class='line'>{
</span><span class='line'>        struct trace_event_file *file = data;
</span><span class='line'>
</span><span class='line'>        WARN_ON(!(call-&gt;flags & TRACE_EVENT_FL_TRACEPOINT));
</span><span class='line'>        switch (type) {
</span><span class='line'>        case TRACE_REG_REGISTER:
</span><span class='line'>                return tracepoint_probe_register(call-&gt;tp,
</span><span class='line'>                                                 call-&gt;class-&gt;probe,
</span><span class='line'>                                                 file);
</span><span class='line'>...</span></code></pre></td></tr></table></div></figure>


<p>The probe function <code>call-&gt;class-&gt;probe</code> for trace events is defined in the file <code>include/trace/trace_events.h</code> and does the job of writing to the ring buffer. In a nutshell, the code gets a handle into the ring buffer, does assignment of the values to the entry structure and writes it out. There is some magic going on here to accomodate arbitrary number of arguments but I am yet to figure that out.</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>static notrace void                                                     \
</span><span class='line'>trace_event_raw_event_##call(void *__data, proto)                       \
</span><span class='line'>{                                                                       \
</span><span class='line'>        struct trace_event_file *trace_file = __data;                   \
</span><span class='line'>        struct trace_event_data_offsets_##call __maybe_unused __data_offsets;\
</span><span class='line'>        struct trace_event_buffer fbuffer;                              \
</span><span class='line'>        struct trace_event_raw_##call *entry;                           \
</span><span class='line'>        int __data_size;                                                \
</span><span class='line'>                                                                        \
</span><span class='line'>        if (trace_trigger_soft_disabled(trace_file))                    \
</span><span class='line'>                return;                                                 \
</span><span class='line'>                                                                        \
</span><span class='line'>        __data_size = trace_event_get_offsets_##call(&__data_offsets, args); \
</span><span class='line'>                                                                        \
</span><span class='line'>        entry = trace_event_buffer_reserve(&fbuffer, trace_file,        \
</span><span class='line'>                                 sizeof(*entry) + __data_size);         \
</span><span class='line'>                                                                        \
</span><span class='line'>        if (!entry)                                                     \
</span><span class='line'>                return;                                                 \
</span><span class='line'>                                                                        \
</span><span class='line'>        tstruct                                                         \
</span><span class='line'>                                                                        \
</span><span class='line'>        { assign; }                                                     \
</span><span class='line'>                                                                        \
</span><span class='line'>        trace_event_buffer_commit(&fbuffer);                            \
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>Let me know any comments you have or any other ftrace event behavior you&rsquo;d like explained.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/blog/2016/03/20/tif-need-resched-why-is-it-needed/">TIF_NEED_RESCHED: Why Is It Needed</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2016-03-20T01:44:32-07:00" pubdate data-updated="true">Mar 20<span>th</span>, 2016</time>
        
           | <a href="/blog/2016/03/20/tif-need-resched-why-is-it-needed/#disqus_thread"
             data-disqus-identifier="http://www.linuxinternals.org/blog/2016/03/20/tif-need-resched-why-is-it-needed/">Comments</a>
        
      </p>
    
  </header>


  <div class="entry-content"><p><code>TIF_NEED_RESCHED</code> is one of the many &ldquo;thread information flags&rdquo; stored along side every task in the Linux Kernel. One of the flags which is vital to the working of preemption is <code>TIF_NEED_RESCHED</code>. Inorder to explain why its important and how it works, I will go over 2 cases where <code>TIF_NEED_RESCHED</code> is used.</p>

<h2>Preemption</h2>

<p>Preemption is the process of forceably grabbing CPU from a user or kernel context and giving it to someone else (user or kernel). It is the means for timesharing a CPU between competing tasks (I will use task as terminology for process).
In Linux, the way it works is a timer interrupt (called the tick) interrupts the task that is running and makes a decision about whether a task or a kernel code path (executing on behalf of a task like in a syscall) is to be preempted. This decision is based on whether the task has been running long-enough and something higher priority woke up and needs CPU now, or is ready to run.</p>

<p>These things happen in <code>scheduler_tick()</code>, the exact path is <em>TIMER HARDWARE INTERRUPT</em> &ndash;> <code>scheduler_tick</code> &ndash;> <code>task_tick_fair</code> &ndash;> <code>entity_tick</code> &ndash;> <code>check_preempt_tick</code>.
<code>entity_tick()</code> updates various run time statistics of the task, and <code>check_preempt_tick()</code> is where TIF_NEED_RESCHED is set.</p>

<p>Here&rsquo;s a small bit of code in <code>check_preempt_tick</code></p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>check_preempt_tick(struct cfs_rq *cfs_rq, struct sched_entity *curr)
</span><span class='line'>{
</span><span class='line'>        unsigned long ideal_runtime, delta_exec;
</span><span class='line'>        struct sched_entity *se;
</span><span class='line'>        s64 delta;
</span><span class='line'>
</span><span class='line'>        ideal_runtime = sched_slice(cfs_rq, curr);
</span><span class='line'>        delta_exec = curr-&gt;sum_exec_runtime - curr-&gt;prev_sum_exec_runtime;
</span><span class='line'>        if (delta_exec &gt; ideal_runtime) {
</span><span class='line'>                resched_curr(rq_of(cfs_rq));
</span><span class='line'>                /*
</span><span class='line'>                 * The current task ran long enough, ensure it doesn't get
</span><span class='line'>                 * re-elected due to buddy favours.
</span><span class='line'>                 */
</span><span class='line'>                clear_buddies(cfs_rq, curr);
</span><span class='line'>                return;
</span><span class='line'>        }</span></code></pre></td></tr></table></div></figure>


<p>Here you see a decision is made that the process ran long enough based on its runtime and if so call <code>resched_curr</code>. Turns out <code>resched_curr</code> sets the <code>TIF_NEED_RESCHED</code> for the current task! This informs whoever looks at the flag, that this process should be scheduled out soon.</p>

<p>Even though this flag is set at this point, the task is not going to be preempted yet. This is because preemption happens at specific points such as exit of interrupts. If the flag is set because the timer interrupt (scheduler decided) decided that something of higher priority needs CPU now and sets <code>TIF_NEED_RESCHED</code>, then at the exit of the timer interrupt (interrupt exit path), <code>TIF_NEED_RESCHED</code> is checked, and because it is set &ndash; <code>schedule()</code> is called causing context switch to happen to another process of higher priority, instead of just returning to the existing process that the timer interrupted normally would.
Lets examine where this happens.</p>

<p>For return from interrupt to user-mode:</p>

<p>If the tick interrupt happened user-mode code was running, then in somewhere in the interrupt exit path for x86, this call chain calls schedule <code>ret_from_intr</code> &ndash;> <code>reint_user</code> &ndash;> <code>prepare_exit_to_usermode</code>. Here the need_reched flag is checked, and if true <code>schedule()</code> is called.</p>

<p>For return from interrupt to kernel mode, things are a bit different (skip this para if you think it&rsquo;ll confuse you).</p>

<p>This feature requires kernel preemption to be enabled. The call chain doing the preemption is: <code>ret_from_intr</code> &ndash;> <code>reint_kernel</code> &ndash;> <code>preempt_schedule_irq</code> (see <code>arch/x86/entry/entry_64.S</code>) which calls <code>schedule</code>.
Note that, for return to kernel mode, I see that <code>preempt_schedule_irq</code> calls <code>schedule</code> anyway whether need_resched flag is set or not, this is probably Ok but I am wondering if need_resched should be checked here before <code>schedule</code> is called. Perhaps it would be an optimiziation to avoid unecessarily calling <code>schedule</code>. One reason for not doing so would be, say any other interrupt other than timer tick is returning to the interrupted kernel space, then in these cases for example &ndash; if the timer tick didn&rsquo;t get a chance to run (because all other local interrupts are disabled in Linux until an interrupt finishes, in this case our non-timer interrupt), then we&rsquo;d want the exit path of the non-timer interrupt to behave just like the exit path of the timer tick interrupt would behave, whether need_resched is set or not.</p>

<h2>Critical sections in kernel code where preemption is off</h2>

<p>One nice example of a code path where preemption is off is the <code>mutex_lock</code> path in the kernel. In the kernel, there is an optimization where if a mutex is already locked and not available, but if the lock owner (the task currently holding the lock) is running on another CPU, then the mutex temporarily becomes a spinlock (which means it will spin until it can get the lock) instead of behaving like a mutex (which sleeps until the lock is available). The pseudo code looks like this:</p>

<figure class='code'><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
</pre></td><td class='code'><pre><code class=''><span class='line'>mutex_lock() {
</span><span class='line'>  disable_preempt();
</span><span class='line'>  if (lock can't be acquired and the lock holding task is currently running) {
</span><span class='line'>  while (lock_owner_running && !need_resched()) {
</span><span class='line'>      cpu_relax();
</span><span class='line'>  }
</span><span class='line'>  }
</span><span class='line'>  enable_preempt();
</span><span class='line'>  acquire_lock_or_sleep();
</span><span class='line'>}</span></code></pre></td></tr></table></div></figure>


<p>The lock path does exactly what I described. <code>cpu_relax()</code> is arch specific which is called when the CPU has to do nothing but wait. It gives hints to the CPU that it can put itself into an idle state or use its resources for someone else. For x86, it involves calling the <a href="https://en.wikipedia.org/wiki/HLT">halt instruction</a>.</p>

<p>What I noticed is the Ftrace latency tracer complained about a long delay in the preempt disabled path of mutex_lock for one of my tests, and I made some <a href="http://www.spinics.net/lists/linux-rt-users/msg15022.html">noise</a> about it on the mailing list. Disabling preemption for long periods is generally a bad thing to do because during this duration, no other task can be scheduled on the CPU. However, Steven <a href="http://www.spinics.net/lists/linux-rt-users/msg15025.html">pointed out that</a> for this particular case, since we&rsquo;re checking for need_resched() and breaking out of the loop, we should be Ok. What would happen is, the scheduling timer interrupt (which calls <code>scheduler_tick()</code> I mentioned earlier) comes in and checks if higher priority tasks need CPU, and if they do, it sets <code>TIF_NEED_RESCHED</code>. Once the timer interrupt returns to our tightly spinning loop in mutex_lock, we would break out of the loop having noticed <code>need_resched()</code> and, re-enable preemption as shown in the code above. Thus the long duration of preemption doesn&rsquo;t turn out to be a problem as long tasks that need CPU are prioritized correctly. <code>need_resched()</code> achieved this fairness.</p>

<p>Next time you see <code>if (need_resched())</code> in kernel code, you&rsquo;ll have a better idea why its there :). Let me know your comments if any.</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/blog/page/2/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/blog/2016/12/31/nmi-perf-armv8/">ARMv8 and NMI Support</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/06/18/ftrace-events-mechanism/">Ftrace Events Mechanism</a>
      </li>
    
      <li class="post">
        <a href="/blog/2016/03/20/tif-need-resched-why-is-it-needed/">TIF_NEED_RESCHED: Why Is It Needed</a>
      </li>
    
      <li class="post">
        <a href="/blog/2015/12/25/tying-2-voltage-sources-slash-signals-together/">Tying 2 Voltage Sources/signals Together</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/06/04/a-microsd-card-remote-switcher/">MicroSD Card Remote Switch</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/05/07/spinlock-implementation-in-linux-kernel/">Linux Spinlock Internals</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/24/studying-cache-line-sharing-effects-on-smp-systems/">Studying Cache-line Sharing Effects on SMP Systems</a>
      </li>
    
      <li class="post">
        <a href="/blog/2014/04/22/design-of-fork-followed-by-exec-in-linux/">Design of Fork Followed by Exec in Linux</a>
      </li>
    
  </ul>
</section>





  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2016 - Joel Fernandes -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'linuxinternals1';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = '//' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>
